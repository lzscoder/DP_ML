{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用sigmoid函数作为激励函数,sigmoid函数的特点是S型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def tanh_deriv(x):\n",
    "    return 1.0 - np.tanh(x)*np.tanh(x)\n",
    "def logistic(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def logistic_derivative(x):\n",
    "    return logistic(x)*(1-logistic(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,layers,activation = 'tanh'):\n",
    "        if activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_deriv = tanh_deriv\n",
    "        elif activation == 'logistic':\n",
    "            self.activation = logistic\n",
    "            self.activation_deriv = logistic_derivative\n",
    "        \n",
    "        self.weights = []\n",
    "        \"\"\"这里形成的最下面一行和最右边的一列其实是为bias准备的\"\"\"\n",
    "        #以XOR为例\n",
    "        #     * * *    *\n",
    "        #     * * *    *\n",
    "        #     % % %    %       (参数的形式)\n",
    "        \n",
    "        #     ￥ ￥ ￥         (输入值的形式，最后一个值是新加的，为1)\n",
    "        #     ￥%+￥%+￥%      完成了Ij = ∑WijOi + θj\n",
    "        #      并且最后一次的  ￥%+￥%+￥% 生成了新的￥值\n",
    "        for i in range(1,len(layers)-1):\n",
    "            self.weights.append((2*np.random.random((layers[i-1]+1,layers[i]+1))-1)*0.25)\n",
    "            self.weights.append((2*np.random.random((layers[i]+1,layers[i+1]))-1)*0.25)\n",
    "    \n",
    "    def fit(self,X,y,learning_rate = 0.2,epochs = 10000):\n",
    "        \"\"\"X在下面的操作后会变成np.array以及在最后增加了一列\"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        temp = np.ones([X.shape[0],X.shape[1]+1])\n",
    "        temp[:,0:-1] = X\n",
    "        X = temp\n",
    "        y = np.array(y)\n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "            \"\"\"a最初是随机选取的一行数据，把当做输入值，但是要使用激励函数\"\"\"\n",
    "            \"\"\"把每一层的计算结果都加载列表a的最后面，每一层的计算都要使用前一层的结果\"\"\"\n",
    "            for L in range(len(self.weights)):\n",
    "                a.append(self.activation(np.dot(a[L],self.weights[L])))\n",
    "            \"\"\"error是预测与标签的偏差\"\"\"\n",
    "            error = y[i]-a[-1]\n",
    "            \"\"\"第一次是计算输出层的Err\"\"\"\n",
    "            \"\"\"输出层的公式：Errj = Oj(1-Oj)(Tj-Oj)\"\"\"\n",
    "            \"\"\"这里的error是(Tj-Oj),而self.activation是Oj(1-Oj)\"\"\"\n",
    "            deltas = [error * self.activation_deriv(a[-1])] #For output layer, Err calculation (delta is updated error)\n",
    "            \n",
    "            #Staring backprobagation\n",
    "            \"\"\"隐藏层的公式:Errj = Oj(1-Oj)∑ErrK*weights(JK)\"\"\"\n",
    "            for l in range(len(a) - 2, 0, -1): # we need to begin at the second to last layer \n",
    "                #Compute the updated error (i,e, deltas) for each node going from top layer to input layer \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))  \n",
    "            deltas.reverse()#反转操作是必要的\n",
    "            \"\"\"正向对权重以及偏差进行更新\"\"\"\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])  \n",
    "                delta = np.atleast_2d(deltas[i])  \n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "    def predict(self, x):         \n",
    "        x = np.array(x)\n",
    "        temp = np.ones(x.shape[0]+1)\n",
    "        temp[0:-1] = x\n",
    "        a = temp\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([2,2,1], 'tanh') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始对神经网络进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,0])\n",
    "nn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 1\n",
      "[1, 0] 1\n",
      "[1, 1] 0\n"
     ]
    }
   ],
   "source": [
    "pre = []\n",
    "for i in [[0, 0], [0, 1], [1, 0], [1,1]]:    \n",
    "    a = nn.predict(i)\n",
    "    if a<0.5:\n",
    "        a=0\n",
    "    else:\n",
    "        a=1\n",
    "    print(i,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.preprocessing import LabelBinarizer #对数据进行转化例如 2-> 00000010\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X -= X.min()\n",
    "X /= X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fitting\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([64,100,10],'logistic')\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "labels_train = LabelBinarizer().fit_transform(y_train)\n",
    "labels_test = LabelBinarizer().fit_transform(y_test)\n",
    "print(\"start fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  0  0  0  0  0  0  0  0  0]\n",
      " [11 33  0  0  4  0  0  0  0  1]\n",
      " [ 1  1 32  0  0  0  0  1  0  0]\n",
      " [14  0  0 26  0  0  0  2  1  2]\n",
      " [ 0  0  0  0 48  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 48  0  0  0  0]\n",
      " [ 0  2  0  0  1  0 34  0  0  0]\n",
      " [ 1  0  0  0  0  0  0 40  0  1]\n",
      " [ 6  3  0  0  5  2  0  0 29  0]\n",
      " [ 1  0  0  0  0  0  0  3  1 43]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      1.00      0.76        53\n",
      "          1       0.85      0.67      0.75        49\n",
      "          2       1.00      0.91      0.96        35\n",
      "          3       1.00      0.58      0.73        45\n",
      "          4       0.83      1.00      0.91        48\n",
      "          5       0.96      1.00      0.98        48\n",
      "          6       1.00      0.92      0.96        37\n",
      "          7       0.87      0.95      0.91        42\n",
      "          8       0.94      0.64      0.76        45\n",
      "          9       0.91      0.90      0.91        48\n",
      "\n",
      "avg / total       0.89      0.86      0.86       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn.fit(X_train,labels_train,3000)\n",
    "predictions = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    o = nn.predict(X_test[i])\n",
    "    predictions.append(np.argmax(o))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
